Chapter 1 Introduction

From the debut of the first simulator, people have kept asking the same question: "How realistic the simulation result can be?" The reason for asking this question is quite reasonable, because a simulator is actually useless if it cannot mimic the behaviors of the real thing. In the simulator's world, the words like accuracy or exactness are normally used to describe how realistic a test result is. To achieve accuracy, developers have made several efforts in the past decade or so. The focus, however, has been primarily on the use of real network stacks. As can be seen from some previous tests, a highly abstract network stack makes the test result neither convincing nor realistic. Undoubtedly, a real world network stack is the most critical part of a realistic network simulator, but it is not the only part to achieve accuracy. The modern network simulators are quite complex systems and the other parts of a simulator such as event scheduler, timing, queuing and application layer, can also affect the final results of simulations. Among these factors, there are increased interests in the application layer of simulator.

1.1 Why $ pplication Layer Is so Important
In the real world, different data sources make network stack behave differently which, therefore, affects network performance in different ways. When investigating the performance of network stack, it is unavoidable to associate such kind of investigation with a specific data source. The interaction between application layer and network stack is a major topic in networking history and will be more important in future. The traditional HTTP 1.0 over TCP problem is perhaps, the clearest instance to demonstrate how application layer affects performance of network layer. The HTTP 1.0 protocol creates a new TCP connection for each item that it requests from server. If, for example, a page contains nothing except three images, it will result in four TCP connections - one for the page itself and three others for each of the images. This is inefficient in terms of bandwidth utilization. A three-way handshake process is needed to set up a connection, and two additional
1

packets are required to close it. Even for a very simple page, the burden of setting up and tearing down of connections are still considerably heavy. Another problem with the HTTP 1.0 is the poor bandwidth utilization incurred by the slow start mechanism. Instead of transmitting packets as fast as possible, the HTTP 1.0 sets the TCP window size to one segment initially. The TCP window size doubles each time a whole window of packets are transferred successfully. This mechanism works fine when the connection is long-lived, but for short-lived connections this slow start mechanism is quite inefficient in terms of network bandwidth utilization. Several studies have shown that the vast majority of web accesses retrieve small files, on the order of 6 KB [15] [16]. In other words, if the payload of packet is 1500 bytes in size, a 6K bytes web page needs only 4 packets. Because slow start is initialized each time when a connection is created, so for most HTTP 1.0 connections it always works at very low data rate and utilizes network bandwidth poorly. Unfortunately, in spite of tremendous development in technology, the modern world still suffers the same problem as the old HTTP 1.0 did. The Internet is now increasingly being used to deliver real time data such as video-conferencing, streaming, HDTV, P2P and so on. Most of real time applications are now running on top of UDP, which is a highly efficient, but unreliable transport layer protocol. The real time UDP packets may experience different bandwidth and congestion conditions, so an annoying drawback with UDP is the data loss. For some real time communications, data loss can affect Quality of Service (QoS) significantly and thus, is difficult to tolerate. In video-conferencing, the data being transferred is typically significantly compressed to save network bandwidth, and this makes it very sensitive to data loss. A single packet loss corrupting an I-frame can stop reception of video for several seconds. To achieve high QoS, other reliable transport layer protocols such as TCP have to be considered. TCP is the most well developed, extensively used and widely available Internet transport protocol. TCP is reliable and responsive to network congestion conditions. Another reason to choose TCP to run real time applications is the reality that many firewalls reject all non-TCP traffic. On the other hand, the fatal drawback of TCP is its low efficiency compared to UDP. TCP is not suitable for transmitting real time traffic because it favors reliable delivery over timely delivery. Both TCP and UDP are not perfect for transmitting real time multimedia data. To adapt to future network environment, TCP and UDP have to be modified or even new protocols will have to be introduced into transport layer such as Stream Control Transmission Protocol (SCTP). Thus, network applications affect the performance of network stack and even
2

make the network stack to be modified. Application layer is critical to network performance. However, in simulators data sources are implemented using very simple model and have nothing to do with real world network applications. There are several drawbacks with such simulated user applications.

1.2 Limitations of Simulated Applications
Simulated applications are usually over-simplified and network simulators take a simple way to implement data sources. Timer is usually used to control when to send out the next message. After starting the application, a timer is initialized to wait for a short period of time and an event handler is set to handle timeout events. When the timer expires, simulator's scheduler invokes the indicated event handler, which, in turn, sends out messages and then resets timer for the next message. In the NS-2, a simulated "telnet" is just about 30 lines of C++ code. Such implementation is not programmed using real world application code such as BSD Socket API; and even worse, many details of real world network applications are ignored intentionally to facilitate designing. The question, therefore, remains as to what extent such over-simplified simulated applications mimic the behaviors of real world network applications. In the real world, countless network applications are available. These come with either source code or only binaries, but just limited amount of applications are provided in simulators. At times, new applications in simulator have to be created by extending the existing application class. For example, in NS-2 you can derive your own application class from the existing class "Application". Such implementations are still employing over-simplified model and time-consuming. The simulated applications are neither realistic nor sufficient. Thus, to solve this problem, a new model called "BSD Socket API for Simulator" is proposed here to run untouched real world network application binaries on top of general-purpose Simulators.

1.3 BSD Socket API for Simulator
Running real world code on top of simulator has been implemented in several projects such as embedded network simulator, ENTRAPID, Alpine, NCTCns, and Lunar. All of these projects, however, have some limitations such as: Some of the projects, such as embedded network simulator and NCTUns, need the simulator to be integrated into kernel. Only simple simulators can be used in such project as these cannot make full use of the powerful functionality and versatile tools provided by modern general-purpose
3

simulators such as NS-2, Omnet++ and JSim. Some of the projects, such as ENTRAPID and Lunar, need the real world applications to be recompiled and re-linked against some special libraries. This approach is not working for those real world applications that do not come with source codes. Some of the projects, such as Alpine and NCTUns, need root privileges. All of the projects use exclusive simulators On the other hand, the BSD Socket API for Simulator is designed to eliminate most of these drawbacks. It is fully compatible with BSD Socket API, simulator independent, transparent to real world applications and it keeps the original real world application binaries untouched.

1.4 Contributions of this Thesis
The achievements of the BSD Socket API for Simulator are as follows: A new simulation framework is designed and implemented. The new model is based on the concept of "message redirecting". Real world applications redirect messages by loading customized shared libraries. Simulator exchanges information with the shared libraries through its customized application layer. A multi-threaded simulator application layer is implemented. The single thread simulator, NS-2, does not suit for running unmodified real world applications due to the existence of blocked calls. To solve the problem, a multi-threaded model is proposed and a multi-threaded simulator application layer is implemented. A shared library is implemented as the interface of real world applications to redirect messages to simulator. The shared library is loaded into the address space of real world application. It catches the socket related calls and redirects them to simulator. Unit tests have testified that the 29 socket-related functions in the shared library are compatible with their counterparts in the BSD Socket API. Three groups of real world applications are run on top of the BSD Socket API for Simulator as functional tests. Efficiency tests are done to measure to what degree the BSD Socket API for Simulator slows down simulations.

1.5 The Rest of this Document
Chapter 2 "Background" introduces background of this project. Some previous works are presented and their advantages and disadvantages are
4

analyzed. Among the previous works, the Network Simulation Cradle (NSC) is explained in detail. Chapter 3 "Architecture Overview" explains briefly how the two major parts of the project, namely, the simulator application pair and the BSD Socket API shared library, are implemented and how they interact with each other. Chapter 4, "Multi-threaded Simulator Application Pair", describes why the multi-threaded simulator application pair is necessary in this project, how it is implemented and the mechanism employed to balance work load among multiple simulator application pairs. Chapter 5 "Shared Library" is core to this document. This chapter describes the procedure to set up and tear down basic TCP and UDP connections; and introduces the implementations of various sending and receiving functions such as send(), recv(), sendto(), recvfrom(), sendmsg() and recvmsg(); closeing socket by close () and shutdown (); I/O multiplexing by select(), pselect() and poll(); running standard I/O library functions over sockets; getting and setting socket options. Chapter 6 "Tests" introduces unit tests, functional tests and efficiency tests done in this project. Chapter 7 "Limitations and Future Works" analyzes limitations of "BSD Socket API for Simulator" and what else can be done to improve it in future works. Appendix A "Function list" shows all the socket-related function prototypes implemented in the BSD Socket API for Simulator shared library. Appendix B "Kernel Data Structures" lists data structures being moved out of kernel. Due to the name conflict when compiling the BSD Socket API for Simulator, some kernel data structures have to be moved to a user-level header file. Appendix C "Modifications to code from UNIX Network Programming". Examples from "Unix Network Programming" [W. Richard Stevens et al] are supposed to run on UNIX, but the BSD Socket API for Simulator is running on Linux. So when compiling the code on Linux, a number of "Symbol missing" errors occurred. To eliminate such errors, some symbols are defined.

5

Chapter 2 Background

Running real world applications on top of simulator is not a new effort, but organizing powerful general-purpose modern network simulator, real world network stack and real world application in one system is new to the world. In this chapter, some related past works are reviewed; advantages and disadvantages of each work are analyzed. Subsequently, the Network Simulation Cradle (NSC) is introduced in depth. The NSC is the first effort ever to integrate general purpose simulator with real world network stack and is chosen to be the base of the BSD Socket API for Simulator.

2.1 Past works
From the perspective of network simulator history, the efforts of using real world network stack and the efforts of running real world application on top of simulator are closely related. Each of the following past works is reviewed from two aspects: the way the real world network stack is integrated with simulator and the way the real world application is integrated with real world network stack.

2.1.1 Embedded Network Simulator
The Embedded network simulator [Luigi Rizzo, 1997] is a protocol development environment. To make use of the advantages of network simulator and experimental test bed, this project proposes to embed network simulator in operational systems. A simulator is built in kernel at the interface between TCP and IP. The embedded simulator intercepts calls between the two layers and generates the effects of queues, bandwidth limitations, delays and noises. Not surprisingly, such system enables real world network applications to run without the need of modification. Embedded network simulator moves simulator into kernel instead of moving network stacks out of kernel. In the past when simulators were simple and of limited functionality, this approach was viable. Actually, the first simulator built in this project was only 300 lines of code. The limitations of this approach are the need of modifications to all the kernels in
6

which the simulators will be running and the efficiency cost when the simulators are quite complex. It is impossible to build a modern simulator such as NS-2 or Omnet++ inside kernel, not mentioning the simulators using JAVA like J-Sim.

2.1.2 ENTRAPID

ENTRAPID [X.W. Huang et al. 1999] is a real time network simulator and a Protocol Development Environment (PDE) as well. Unlike the previous embedded network simulator, the ENTRAPID is nothing but a user space process. It is built on two concepts: Virtualized Networking Kernel (VNK) and Virtualized Process. VNK is the 4.4 BSD network stacks, which is moved out of kernel and modified to let it run in user space. By means of kernel virtualization, an ENTRAPID process can contain multiple VNKs. Applications are also virtualized to run on top of VNK. System calls issued by virtualized applications are redirected to VNKs. ETRAPID can also control physical network devices to communicate with external processes. ENTRAPID can organize a quite complex and powerful test framework, but it has some limitations. Firstly, the network kernel is modified manually. The process of moving the stack out of kernel is quite a lot of work and it is hard to keep the modified stack up to date. Secondly, the ENTRAPID cannot run unmodified programs. The program's source code is linked with a proxy library that first converts networking and file system calls to messages, and then sends the messages to a virtualized process. Subsequently, the virtualized process decodes the message and executes the network or file system calls in the context of ENTRAPID. Thirdly, because a message from an application is copied to VNK, from VNK to wire, from wire to another VNK, from VNK to destination application, so ENTRAPID lacks efficiency.

2.1.3 Alpine

Alpine [David Ely et al. 2001] is a user-level infrastructure for network protocol development. Alpine converts FreeBSD 3.3 network stack into a user-level shared library with a few hand modifications. There are two critical modifications that need to be mentioned. The first one is to add a new layer under the IP layer called "Faux-Ethernet Driver" to the shared library. This new layer is the lowest layer of the shared library, it is used to send packets using a raw socket and receive packet using a packet capture tool (libpcap).
7

The second modification is to add a new layer on top of the system call layer. The new layer is the topmost layer of the shared library. The new layer implements a new programming interface to replace the traditional system calls. This layer captures all the system calls on socket descriptors or file descriptors and deals with them transparently. Alpine moves network stack out of kernel with fewer efforts than embedded network simulator and ENTRAPID. Another attractive feature of Alpine is that application binaries can run on top of it without the need of recompiling and re-linking. There are, however, two drawbacks for Alpine. Firstly, some operations, like opening a raw socket, capturing packets by libpcap, need root privileges; secondly, the fork() system call is not implemented inside the new application interface layer, a large portion of network applications cannot run on Alpine.

2.1.4 NCTUns

NCTUns [S.Y Wang et al. 2003] is a real time network emulator and simulator. Instead of moving network stack out of kernel, NCTUns keeps network stack where it was but modified by hand to integrate simulation functionality into kernel. NCTUns takes a similar way as that of embedded network simulator. Tunnel Network Interface is key to NCTUns and is a pseudo network interface that does not have a real physical network attached to it. The interface has a corresponding device special file in the /dev directory. When applications write to the special file, the packet enters the kernel. To the kernel, there is no difference between packets from a real interface and that from the tunnel network interface. A read from the tunnel network interface causes one packet to be copied from kernel to user space and passed to the reading application. Therefore, the tunnel network interface behaves completely the same way as the real network interface. Besides real world network stack, another benefit NCTUns provides is the ability to run unmodified real world network applications and real world network utility programs by exposing the standard UNIX POSIX API. There are, however, several drawbacks of NCTUns: the first one is the scalability limitation, because there is only one network stack on a host, to simulate a complex network with different network stacks will need multiple hosts and a distributed test environment. The second limitation is that the user needs root privileges to modify and recompile the kernel and run simulations.

8

2.1.5 Lunar

Lunar [Christopher C. Knestrick. 2004] is a Linux User-level Network Architecture. Lunar is designed as part of Open Network Emulator (ONE), a large-scale network emulation test-bed. In Lunar, the network stack of Linux operating system (2.4.3 version of the Linux kernel) is extracted and compiled as a user-level library. The shared library provides an interface which implements the BSD socket API and related functions. The unmodified real world application source code is recompiled and re-linked against Lunar's shared library. Lunar acts as an interface between user applications and network simulator. Network traffic is generated using real-world programs and regulated by network simulator. Lunar combines the benefits of direct code execution with the control and scalability of modern network simulator. In Lunar, real world applications have to be recompiled and linked against Lunar before running. The real world applications which source codes are not available cannot run on Lunar.

2.1.6 Network Simulation Cradle
Network Simulation Cradle (NSC) [Sam Jansen. 2005], like Alpine and Lunar, moves network stack out of kernel and compiles it as a shared library. The NSC uses the shared library to create Agent for NS-2 network simulator. NSC integrates real world network stacks with the NS-2 by creating an NSC agent. The agent creates, initializes and interacts with real world network stacks. The network stacks themselves become part of the network simulator. Real world network stacks are modified automatically using a tool, so there is no manual modification in NSC. Multiple modified network stacks can be run in the same simulation and on the same physical machine. The disadvantage, however, of NSC is that it still uses the simulated applications to generate network traffic. NS-2's applications are simply instances of some C++ classes employing quite simple model.

9

2.1.7 Characteristics of Past Works

The following Table summarizes the characteristics of past works in terms of simulator, network stack and application. Name Embedded Network Simulator ENTRAPID Simulator In kernel Simple Exclusive In user space Exclusive In user space Exclusive Network stack In kernel Modified by hand In user space Modified by hand In user space Modified by hand Shared library In kernel Modified by hand Application (1) Run unchanged real world application (1) Real world application's source code is compiled and linked against a proxy library (1) Only run part of unchanged real world programs (2) Need root privileges (1) Run unchanged real world application (2) Need root privileges (1) Real world application's source code is compiled and linked with a user-level library (1) Simulated Application

Alpine

NCTUns

In kernel Exclusive In user space Exclusive

Lunar

NSC

In user space slightly modified user-level library In user space In user space Eeneral-purpose slightly modified user-level library Table 2.1 Characteristics of Past Works

From the above table, there are some options for three interesting aspects of past works. These options lead to different features. Simulator can be in user space or in kernel. In kernel simulator is usually functionally limited and it is a painful process to debug the simulator or add new features. Simulator can be exclusive or general-purpose; the exclusive simulator is built to meet some special needs, so it does not contain versatile tools provided by general-purpose simulators. Network stack can be in kernel or user space. In kernel network, stack suffers the same problem as that of in kernel simulator. Besides, in kernel network stack is not scalable. In user space network, stack is usually compiled as a library. It increases the flexibility and scalability. Application can be:
10

(1) Untouched real word code. (2) Untouched real world code but need special conditions such as root privileges. (3) Real world code but need to be recompiled and re-linked. (4) Simulated application. It is, therefore, obvious that the "untouched real world code" is the ideal solution.

2.2 Goals of BSD Socket API for Simulator
To eliminate limitations of past works and distinguish the BSD Socket API for Simulator with previous works, several goals are set up for BSD Socket API for Simulator. 1. BSD Socket API for simulator is completely compatible with BSD Socket API. Socket API is part of IEEE1003.1g standard, which is also called POSIX.1g. Most UNIX and Linux systems today conform to Portable Operating System Interface (POSIX). Socket API has been a networking standard for UNIX-like systems. BSD Socket API for Simulator is simulator independent. Currently, the BSD Socket API for Simulator is developed and tested on NS-2, and it is supposed to be moved to other general-purpose simulators such as Omnet++ with trivial works. It can make use of the powerful functionality and tools provided by general-purpose simulators. BSD Socket API for Simulator keeps real world application binaries untouched, no recompilation and re-linking are necessary before running them. BSD Socket API for Simulator is transparent for real world applications. These applications run on simulator exactly the same as they do on an operating system. No special conditions, such as root privileges, are necessary when running them.

2.

3.

4.

From table 2.1, an interesting thing worth noting is that NSC is the only attempt ever made to integrate general-purpose simulator with real world network stack. It is the only one that satisfies the second goal of BSD Socket API for Simulator, simulator independent. Besides, NSC has other advantages to make it the best candidate to implement BSD Socket API for Simulator.

11

2.3 Network Simulation Cradle
NSC is the first development of integrating real world stacks with existing general-purpose network simulator. It has been implemented on top of NS-2 and is being transferred to Omnet++. The figure below, taken from "Simulation with Real Network Stacks" [Sam Jansen and Anthony McGregor], shows per-network stack interactions of NSC:

Connect Receive packet NS-2 Simulator Socket send Socket Read Send packet Modify timer Fire timer NSC Agent

Simulator Interface and Support Code

Global Data

Code

Shared Library

Figure 2-1 Per-network stack interactions NSC consists of two parts, NSC agent and shared library that communicate through a well defined interface. There are two tasks for NSC agent. Firstly, it is used to create and interact with another part of NSC, the shared library. Secondly, it is used to interact with other parts of NS-2 simulator such as NS-2's application layer. The shared library contains the network stack and supporting code that implements the interface necessary to communicate with NS-2. NSC has several characteristics that can distinguish it with other past works. 1. Real network stacks are integrated with simulator seamlessly. Real network stack becomes part of simulator. Users create an NSC-agent completely the same as they do with normal NS-2 agents. 2. NSC is simulator independent. NSC does not depend on any specific simulator; theoretically, it can be used with any general-purpose modern network simulator. Originally it was
12

implemented in NS-2, and it is going to work with Omnet++ as well. 3. There is no hand modification to network stack in NSC. A C parser modifies the network stack programmatically to automate the virtualization of network stacks. 4. Different network stacks or multiple instances of the same network stacks can be used in one simulation and on the same host machine. This feature increases the scalability of simulation greatly. NSC is able to employ network stacks from Linux, FreeBSD, OpenBSD and the network stacks designed for embedded systems such as IwIP. NSC is the first effort ever made to make use of the strength of both real network stacks and modern general purpose simulators. Due to its nature of simulator independence, NSC is chosen as the base of the BSD Socket API for Simulator.

2.4 Summary
Several past works are reviewed and their strengths and drawbacks analyzed in terms of simulator, network stack and application. Among the past works, the NSC has some advantages over the others that can best satisfy the need of the BSD Socket API for Simulator and, thus, is chosen as the base of the project.

13

Chapter 3 Architecture Overview

This chapter introduces the overall architecture of BSD Socket API for Simulator. The introduction begins with an abstract block diagram, and then followed by introductions to functions of each items on the diagram including simulator application pair, integrating simulator application pair with NSC, BSD Socket API shared library and the communication between shared library and simulator application pair. BSD Socket API for Simulator consists of two parts: shared library and simulator application pair. The shared library is pre-loaded by setting the environment variable LD_PRELOAD when running real world applications (RWAs). As a result, system calls and function calls on socket descriptors is intercepted and messages contained inside the calls are redirected to simulator by the shared library. The redirected messages are accepted by one side of simulator application pair and then passed down to Network Simulation Cradle (NSC). Subsequent to this, it is the responsibility of simulator and NSC to deal with the message. How the message traverses simulator and NSC will not be discussed here. Actually, it has no difference from those that are passed by normal simulators without NSC. The messages ultimately reach the other end of simulator application pair. The other side of simulator application pair gets the message from NSC's interface and relays it to the destined real world application. The destined real world application has shared library pre-loaded as well. The shared library extracts payload the message originally sent by sender, from the received message. Finally, the payload is passed to the destined real world application.

3.1 Structure of BSD Socket API for Simulator
The BSD Socket API for Simulator is composed of two objects, shared library and simulator application pair. As real world applications and simulator run in different address spaces, to make data flow between source real world application and destination real world application via NS-2, there must be an inter-process communication mechanism. For simplicity, an assumption is made here: the
14

communication mechanism does exist, so different parts of BSD Socket API for Simulator can talk to each other. The inter-process mechanism used in this project will be explained in a following section. The following figure shows the typical data flow of BSD Socket API for Simulator: a source real world application is sending a message out; its destination is another real world application. The arrows show the direction of data flow; solid lines represent inter-process communication; dashed lines represent intra-process communication.

Source RWA Send()

Destination RWA recv()

Source Shared Library

Destination Shared Library

Simulator Application A

Simulator Application B

NSC

NS-2

NSC Inter-Process Intra-Process

Figure 3-1 Structure of BSD Socket API for Simulator Each simulator application has two interfaces: one receives messages from shared library and sends the received message to NSC. The other one receives message from NSC and forwards the received message to shared library. The scenario shown in figure 3.1 is quite straightforward. Both the source and destination RWAs pre-load shared libraries which are called source shared library and destination shared library respectively. System calls or function calls issued by source RWA, such as send () or fputs(), are intercepted by source shared library and processed accordingly. The processing here involves appending extra information, such as where the message comes from and where it is heading to, to the original message contained in the original calls. By this way, each of the intermediate nodes on the route from source RWA to destination RWA will learn
15

about the destination of the message. This extra information will be used by simulator application B when it receives message from NSC agent. It investigates the extra information to obtain the destination address and then relays the message to the destination RWA. The new message is then redirected to simulator and finally reaches simulator application B. The destination application B redirects the received message out of simulator to destination RWA. The destination shared library catches the message sent by simulator application B and copies payload, the message sent by source RWA, to destination RWA's receiving buffer.

3.2 Simulator Application Pair
The process shown in figure 3-1 is actually a bi-directional communication in BSD Socket API for Simulator. The two-way communication is achieved by connecting simulator application A and B together to form a simulator application pair. The simulator application is a multi-threaded implementation. There is one administration thread and multiple serving threads. Each serving thread is responsible for communicating with a specific shared library. One simulator application can serve more than one real world application. In other words, one simulator application pair can serve multiple real world connections. The following diagram shows how simulator application pairs connect real world applications and simulator together.

16

RWA

....

RWA

RWA

....

RWA

RWA

....

RWA

RWA

....

RWA

Simulator Application

Pair-1

Simulator Application

Simulator Application

Pair-2

Simulator Application

NSC

NSC

NS-2
Pair-1 Pair-2
Application Pair Table

NSC

NSC

Inter-Process Intra-Process

Figure 3-2 Simulator application pair In the figure above, there are two simulator application pairs, pair-1 and pair-2. Information about the pairs is stored in application pair table. The application pair table is in shared memory; all the application pairs share the same table. As can be seen from the figure above,