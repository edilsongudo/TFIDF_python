PRACTICE MAKES THE DIFFERENCE: THE EFFECT OF RATE-BUILDING AND RATE-CONTROLLED PRACTICE ON RETENTION

A thesis submitted in fulfillment of the requirements for the degree of Master of Social Sciences at the University of Waikato by SUSAN JENNIFER McGREGOR

University of Waikato 2006

ii

Abstract

Six home-schooled students and one adult participant each initially practiced to accuracy two decks of five previously unknown multiplication facts. The decks were yoked for practice and reinforcement. Once accurate performance was achieved, overpractice was undertaken using custom computer software that allowed either fast (free-operant) or rate-controlled responding. Rate-building practice, to an established fluency performance standard, was used with one deck while practice with the other deck was rate-controlled. The number of times a fact was practiced was the same for both methods. Response rate and accuracy was assessed after training to accuracy, at the end of overpractice and after 4- and 8-weeks of no practice. The assessment at the end of rate-building confirmed that rate-building resulted in fast and accurate responding. It also confirmed that, for the rate-controlled facts, response rates did not meet the fluency performance standard. However, the 4- and 8-week retention assessments showed no consistent differences in accuracy or response rate between the rate-controlled and rate-built decks. After 8 weeks without practice, performance on the rate-built deck was not significantly different to that prior to rate-building. These results suggest that practice to fluency does not lead to superior retention when compared to the same amount of rate-controlled practice. The results also indicate that when a skill is practiced to fluency, a period without practice leads to deterioration, to pre-rate-building levels, of accuracy and response rate. This study highlights the need for research examining the role of maintenance in the effectiveness of fluency based learning like Precision Teaching.

iii

Acknowledgements

My sincerest thanks to my supervisors, Dr Mary Foster, Dr Cath Sumpter and Dr James McEwan. Thank you for all that led up to this thesis, the many lectures and explanations of the intricacies of behaviour analysis. Thank you for your time, you were always available to help, very prompt in reading drafts, remained patient and maintained a sense of humour throughout. Thank you to Tony, Luke and Meaghan, my family and best friends. Thank you for always caring, always believing, always being able to make me laugh and helping me to keep it all in perspective. Thank you for the innumerable big and little things you did to help me to produce this. Thank you to Eric Messick who showed me that behaviour analysis really works. Finally, I would like to thank all those who participated in this study and their families. Thank you for your cooperation, your sense of humour, jokes, piano recitals, delicious baking and perseverance, even when you thought you'd never make it. You were fun to work with and I couldn't have done it without you all.

iv

Contents
Page Abstract Acknowledgements Contents List of Tables List of Figures List of Appendices .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ii iii iv v vi ix

Introduction Method Results Discussion References Appendices Appendix A Appendix B Appendix C Appendix D Appendix E Appendix F Appendix G Appendix H

.. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..

1 32 47 77 95

.. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..

102 103 106 107 108 113 114 115

v

List of Tables

Table 1
Percent inter-observer agreement for all observed sessions for each participant.

Page 47

2

Results for the comparison of the differences between the number of both correct and error responses made in the 1-min timing at each assessment stage.

69

vi

List of Figures

Figure 1 2
Outline of the experimental procedure. The process by which facts are allocated to each of Deck A and Deck B.

Page 37 41

3

Number of practices of each fact during accuracy training (Phase 1) and equalisation (Phase 2) for the five Deck A and five Deck B facts learned for each participant.

49

4

Number of Deck A and Deck B facts answered correctly during card presentations at each assessment session for each participant.

51

5

Rate of both correct and error responses, number of facts answered during a 1-min timing, over the sessions where response rate was assessed during Phases 3 and 4 for P1 and P2 respectively.

53

6

Rate of both correct and error responses, number of facts answered during a 1-min timing, over the sessions where response rate was assessed during Phases 3 and 4 for P3.

54

7

Rate of both correct and error responses, number of facts answered during a 1-min timing, over the sessions where response rate was assessed during Phases 3 and 4 for P4.

55

8

Rate of both correct and error responses, number of facts answered during a 1-min timing, over the sessions where response rate was assessed during Phases 3 and 4 for P5.

56

vii

9

Rate of both correct and error responses, number of facts answered during a 1-min timing, over the sessions where response rate was assessed during Phases 3 and 4 for P6.

57

10

Rate of both correct and error responses, number of facts answered during a 1-min timing, over the sessions where response rate was assessed during Phases 3 and 4 for P7.

58

11

Response rate on 2 times table facts during a single 1-min timing after each training component and at retention assessments.

61

12

Response rate on Deck A facts (trained to accuracy plus fluency) during a single 1-min timing after each training component and at retention assessments.

62

13

Response rate on Deck B facts (trained to an accuracy criterion only) during a single 1-min timing after each training component and at retention assessments.

62

14

Number of correct and error responses made for each Deck A and Deck B fact answered during both un-timed and timed 4- and 8week retention assessments for P1, P2, P3, and P4.

65

15

Number of correct and error responses made for each Deck A and Deck B fact answered during both un-timed and timed 4- and 8-week retention assessments for P5, P6 and P7.

66

16

The mean of all participants' percent frequencies of response latencies for both Deck A and Deck B facts over the four assessment stages. 71

viii

17

The mean of all participants' percent frequencies of response latencies for the deck of 2 times table facts over the four assessment stages.

72

18

The 10th percentile response latencies for each session taken from all trials in that session, during rate-controlled software training on Deck B (rate-controlled) facts.

75

H1

The percent frequencies of response latencies for both Deck A and Deck B facts over the four assessment stages for P1.

116

H2

The percent frequencies of response latencies for both Deck A and Deck B facts over the four assessment stages for P2.

117

H3

The percent frequencies of response latencies for both Deck A and Deck B facts over the four assessment stages for P3.

118

H4

The percent frequencies of response latencies for both Deck A and Deck B facts over the four assessment stages for P4.

119

H5

The percent frequencies of response latencies for both Deck A and Deck B facts over the four assessment stages for P5.

120

H6

The percent frequencies of response latencies for both Deck A and Deck B facts over the four assessment stages for P6.

121

H7

The percent frequencies of response latencies for both Deck A and Deck B facts over the four assessment stages for P7.

122

ix

Appendices

Appendix A
Example of the notice seeking participants posted on the local home-schooling website.

Page 102

B C D E F G H

Information sheet for parents of potential participants. Example of a flashcard used in Phase 1 (accuracy training). Example of Phase 1 (accuracy training) data collection form. Description and specifications of software. Example of Phase 2 (software training) data collection form. Example of Phase 3 (assessment) data collection form. Histograms for each participant, showing the percent frequencies of response latencies for both Deck A and Deck B facts over the four assessment stages.

103 106 107 108 113 114 115

1

Success in education is the foundation for many positive outcomes in life. Unfortunately, for many students, traditional education systems do not produce effective learning outcomes. Precision Teaching (PT) is a behavioural teaching methodology that has shown impressive results, including with students who have been labeled as learning disabled in mainstream education and who have fallen behind two or more grade levels. The effectiveness of Precision Teaching is demonstrated by the ability of some schools to ensure learning gains consistently, to the point where they offer a money-back guarantee to parents that they will raise students' grade levels by two years each school year (Morningside Academy; Johnson & Layng, 1992). These gains have been shown to maintain even when students return to traditional school settings (Johnson & Layng, 1994, p.177). While the effectiveness of Precision Teaching is clear from its outcomes, there has been insufficient scientific study of the methodology to develop a clear understanding of both why the method is effective and what each of the components of this methodology contribute to its effectiveness. At the heart of Precision Teaching is the building of response rates on basic skills to fluency (fluency building). It is claimed that learning skills to fluency has positive learning outcomes (Binder, 1996, 2003; Binder, Haughton & Bateman, 2002; Eshleman, 2001; Haughton, 1984; Johnson & Layng, 1992, 1994, 1996; Kubina & Morrison, 2000; Kubina & Starlin, 2003; Lindsley, 1992; White, 1984). This thesis investigates the relationship between response rate, practice and that most fundamental of learning outcomes, retention.

2 Precision Teaching (PT) Precision Teaching (PT), pioneered by Ogden Lindsley in the 1970s, is a teaching model and measurement paradigm that incorporates effective practice (Bullara, Kimball & Cooper, 1993). It has been used to produce effective learning outcomes with many teaching strategies (Kubina, Morrison & Lee, 2002; Lindsley, 1992) with both adults and children and with both able and differently abled populations (Beck & Clement, 1991; Binder, 1996; Binder, Haughton & Van Eyk, 1995; Haughton, 1997; Johnson & Layng, 1994; Olander, Collins, McArthur, Watts & McDade, 1986). PT came about through dissatisfaction with traditional accuracy-only measures of learning and a desire to use research methods derived from the experimental analysis of behaviour in the education sector (Lindsley, 1992). Precision Teaching is not a single teaching program; it is a method of assessing the success of learning precisely and of adapting teaching to the specific needs of individual students. Teachers make decisions to continue or change teaching strategies and to progress learners to a new learning element based on the behaviour of the learner (Beck & Clement, 1991). PT uses response rate as the primary measure of progress towards skill competency. The response rates of component skills are built to fluency before complex composite skills are introduced. Response rate is measured and built during frequent, daily timed trials, typically of 1-min duration. Data are collected and plotted on Standard Celeration Charts (SCC). Celeration charts provide a pictorial representation of learning that allows analysis of the relationship between changes in performance (both response accuracy and rate) and changes in the learning environment (Lindsley, 1992). They also provide a means of identifying effective and ineffective teaching procedures and a protocol for facilitating informed instructional decisions.

3 Response Rate as a Measure of Behaviour At the heart of PT is the building of free-operant response rates to fluency and the use of response rate as a measure of behaviour. In basic laboratory studies with animals, Skinner discovered that the rate of free-operant responding (frequency) is a sensitive measure of behaviour (Skinner, 1953, pp. 64-68). Free-operant response rates are achieved when the subject's response rate is not limited in any way and the subject is free to respond at any time. Response rate, or frequency, is defined as the number of responses per unit time (Lindsley, 1992). Frequency has been used widely as a measure of behaviour in laboratory settings (Ferster & Skinner, 1957). However, when basic laboratory findings have been applied to educational settings, behaviour analysts have tended to use accuracy measures expressed as percent correct (Binder, 1996; Lindsley, 1992). Accuracy presents just one dimension of competent performance, telling only whether an individual can perform a skill, but not how well. The weakness of accuracy-only measures is their inability to distinguish between expert, and accurate but non-expert performance of a skill (Binder, 2003). A complete description of behavior must include a temporal dimension, since behavior occurs in time. For example, consider two children completing addition sums. Both children may complete `plus one' addition sums with 100% accuracy. However, one child completes sums at a rate of 2 per min and another at a rate of 40 per min. It is clear that one child's performance outweighs the other's. Although the time dimension is frequently omitted from classroom-based learning, it is commonly included in measures of performance in other contexts. Examples include athletics, music and standardised IQ testing (Chiesa & Robertson, 2000).

4 Fluency Building response rates to fluency is a core component of Precision Teaching. In common usage, the term fluency describes behaviour that is accurate, flowing and seemingly effortless (Encarta dictionary, 2005). In behavioural education literature, such as Precision Teaching, fluent behaviour is typically described topographically as "the fluid combination of accuracy plus speed that characterizes competent performance" or "true mastery" (Binder, 1996, p.164). Fluency is defined functionally by Binder (1996) as a `metaphor' describing the observed relationship between response rate and several critical learning outcomes. That is, fluency is defined by its outcomes (Hartnedy, Mozzoni & Fahoum, 2005; Lindsley, 1996). The outcomes most commonly included are retention, endurance and application (Binder, 1996; Binder, 2003; Binder et al., 2002; Eshleman, 2001; Haughton, 1984; Johnson & Layng, 1992, 1994, 1996; Kubina & Morrison, 2000; Kubina & Starlin, 2003; Lindsley, 1992; White, 1984). Some authors suggest that building response rates to fluency also produces the outcomes of stability (stable performance during distraction) and adduction (Johnson & Layng, 1996). Adduction refers to a special case of application where a composite repertoire is established without any direct instruction (Binder, 2004). However, these outcomes are less well accepted and are not the focus of this study. Retention refers to the accurate performance of a learned behaviour long after training has ended. Endurance refers to the ability to perform a behaviour at a competent rate for an extended period of time without a significant decrease in response rate or increase in error rate. The definition of endurance for a particular skill should be related to real-world requirements (Binder, 1996; Binder et al., 1995; Kubina & Morrison, 2000). For example, we may say that a typist exhibits endurance when they maintain a competent typing rate for most of their working day. Application refers to

5 the ease with which fluent component behaviours are combined and applied in the performance of a composite skill (Binder, 2004; Johnson & Layng, 1992; Kubina, 2005). The relationship between the critical learning outcomes and response rate is captured in Haughton's acronym REAPS which stands for: retention, endurance and application performance standards. Performance standards, or fluency aims, specify the particular skill, the modality by which the stimuli are sensed and by which the response is made (learning channel) and the accuracy (quality) and rate (quantity) of the specific response for fluency. Binder et al. (2002) reported "widely accepted" fluency performance standards for twenty-one basic skills (p. 8). The standard given for `see/say' `answers to basic multiplication facts' is `70-100/min' with `near-zero errors'.
Learning channel Skill No. of correct responses per min timing (expressed as a range) Maximum no. of errors accepted

A range of correct responses per min is used to denote fluency. This range covers response rates "within which most learners seem to" show the outcomes of retention, endurance and application (Binder, et al., 2002, p. 8). Precision teaching has been determining and refining fluency performance standards since the 1960s. Precision teaching researchers have determined performance standards for some skills. These performance standards are said to be consistently associated with the following critical learning outcomes: retention, endurance, application (Haughton, 1997; Johnson & Layng, 1994, 1996; Kubina et al., 2002; Kubina & Starlin, 2003; Lindsley, 1996; Luyben, Hipworth & Pappas, 2003). However, Kubina (2005) notes that meeting a fluency performance standard is not the cause of the critical learning outcomes. Rather, attaining fluency provides an indicator of skilled fluent performance which is characterised by retention, endurance and application.

6 Fluency researchers do not use consistent definitions of the critical learning outcomes. Definitions of retention are discussed in more detail later. Binder (2004, p. 284) extends the definition of endurance by adding the criterion that behaviour remain stable, even in the face of distractions that "can potentially compete for stimulus control." Doughty, Chase and O'Shields (2004) suggest that endurance refers to the persistence of high response rates in the face of distraction (e.g., a noisy classroom). However, Binder (2004) cautions that the use of distracters, such as ambient noise, that do not compete for stimulus control do not provide an appropriate assessment of endurance. Doughty et al. (2004) and Weber and Cowardin (1994) incorrectly define application as being synonymous with generalisation, performance of a previously learned skill in an untrained setting, or with another instructor or with non-training stimuli (Binder, 2005; Kubina, 2005). Johnson and Layng (2002) note that when achieving performance standards does not result in application, then application may be taught by creating new environmental contexts for the skill while maintaining fluent response rates (generalisation). Kubina et al. (2002) note that while some authors suggest that developing fluent performance in children with autism enhances the application of learned behaviours to novel situations (generalisation), this relationship has yet to be proven. Both Binder (2004) and Kubina (2005) caution that using incorrect and inconsistent definitions leads to invalid research and may contribute to a lack of understanding of the results. Although most researchers suggest that retention, endurance and application appear when fluency performance standards are met, Johnson and Layng (1992; 1994) and Kubina et al. (2002) state that endurance and application do not necessarily occur unaided as a result of achieving fluency aims. For example, learners may need to build

7 endurance by practicing the skill at the fluency rate for increasingly longer periods of time. Precision Teaching is based on the assumption that complex composite performance is simply the product of a number of simpler component elements. These simpler elements are learned to frequencies specified by performance standards. However, Johnson and Layng (1994) note that application may not occur unaided when these performance standards are met. Games and activities may need to be arranged to promote adduction of these simple elements into more complex composite skills (Johnson & Layng, 1994). Fluent responding is by definition fast, flowing and continuous. Johnson and Layng (1996) state that reference to free-operant response situations must be included in a definition of fluency. Binder (1996) and Johnson and Layng (1996) state that free-operant and not discrete-trial responding is an essential feature of fluent performance. Johnson and Layng (1996) distinguish between discrete trial and free-operant performance. In discrete trial responding, the presentation of the discriminative stimulus is controlled by the experimenter. Typically, a stimulus is presented, a response is made and sometimes the response is reinforced. The experimenter then presents the next discriminative stimulus after an interval of time. Free-operant performance, on the other hand, requires that subjects' response rates are not limited in any way; the subject is free to respond at any time (Binder, 1996; Johnson & Layng, 1996; Wolery, Bailey & Sugai, 1988). Typically in laboratory settings, the discriminative stimulus remains the same, e.g., a key to press. In applied educational settings, typical of PT, the discriminative stimulus is usually varied. Examples include the changing words in a text to be read or different multiplication facts presented on a computer screen. In real-world settings, fluent performances are typically characterised by fast and accurate responding to constantly changing discriminative stimuli.

8 In addition to fluency's relationship to retention, endurance and application, fluent behaviours are advantageous for several reasons. Firstly, fluent behaviours can compete more effectively with previously learned behaviours that serve the same function and achieve the same reinforcers (Wolery et al., 1988). For example, both crawling and walking serve the same function. They allow an individual to move from one place to another. When infants first learn to walk they typically revert to crawling when they wish to get somewhere fast. Crawling is a fluent behaviour, but walking is not yet. When children become fluent at walking they will stop crawling. Fluent walking can effectively compete with crawling. Secondly, when individuals perform behaviours fluently they have more opportunities for positive social reinforcement. For example, when a child reads fluently they will be able to read stories to other children, be able to help others and pass on information from text to others. The child is also less likely to experience the negative social consequences of being unable to read. Further, some behaviours must be performed both accurately and fluently to be useful. For example, a child may be taught the actions involved in swimming accurately but these actions must be performed with sufficient frequency for the child to remain afloat and move through the water.

Fluency Training (Rate-building) Fluency training is a means of building response rates to those of competent performers (Chiesa & Robertson, 2000). In precision teaching, a two stage model of learning a new skill is often proposed: the acquisition stage and the practice stage (Binder, 2003; Miller & Heward, 1992). During the acquisition stage, students learn how to perform a skill accurately with the focus on quality of performance. The ensuing practice stage focuses on the quantitative aspects of performance. During this stage,

9 students repeatedly practice skills during frequent timed trials while attempting to maintain accuracy. Response rates during timed trials are built to a fluency performance standard. This process is typically called fluency training (Hartnedy et al., 2005). Johnson and Layng (1994) state that some learners can build fluency while still acquiring skills; others need to complete accuracy training first. Individual performance data indicates to teachers how learners should progress through this sequence. Haughton (1997) suggests that for some skills it is more beneficial to build rate first and improve accuracy later, e.g., handwriting.

Setting Appropriate Fluency Aims (Performance Standards) Doughty et al. (2004) and Haughton (1997) suggest that fluency building produces high rates of responding (emphasis mine). Binder cautions the use of the term "high response rates" and suggests the use of the term "competent" or "normal ranges of response rate" (Binder, 2004, p. 282). In real life situations, behaviour has a natural speed at which it is most functional to an individual (Ivarie, 1986; Kerr, Smyth & McDowell, 2003). It is this functional response rate that should be represented by performance standards. However, Haughton (1997) states that, to achieve fluency outcomes, some practice must occur at frequencies higher than those measured in competent performance. Much Precision Teaching/fluency research is aimed at establishing specific educational performance standards (Haughton, 1997). While several methods have been proposed, all agree that standards should produce skills that occur at the rate, and for the duration required, in real life situations (i.e., are functional). They should also ensure retention, endurance and application (Binder et al., 1995).

10 While Binder (1996), Doughty et al. (2004) and Haughton (1997) suggest that aims be empirically based, performance standards are typically based on inductive reasoning (Lindsley, 1992). Celeration charts from large samples of students' performance on a particular skill have been used to set performance standards. Consistencies in the range of performance frequencies whose attainment has been followed by retention, endurance and application can be identified in these charts (Binder et al., 2002; Haughton, 1980; Peladeau, Forget, & Gagne, 2003). It should be noted that this evidence is from uncontrolled situations. Results attained from celeration charts lead to hypotheses that can be validated via empirical studies. These empirical studies typically involve building the response rates of participants to those around the hypothesised performance standard range and then evaluating learning outcomes. For example, Evans, Merger and Evans (1983) and Evans and Evans (1985) investigated the relationship between attaining several different frequency criteria on a component skill (saying short `a' and consonant sounds) and subsequent changes in performance during acquisition of the next related skill (saying consonant-vowel-consonant, CVC, trigrams with the letter `a' as the central vowel). After performance frequencies were reached during daily timed trials, participants completed a series of post-test 1-min timings saying CVC trigrams. Gains in response rate from both pre-test to post-test timings and over post-test timings were compared to give an indication of the ease with which the more complex skill was acquired. Their results suggested that, for this task, component skill frequencies of 80-90 responses per minute optimised acquisition. Researchers should be aware that the performance standards necessary to ensure each of the fluency outcomes (retention, endurance and application) may be different. For example, lower rates may ensure retention of math facts, but higher rates may be necessary to ensure application (Binder, 1996).

11 Wolery et al. (1988) surveyed published fluency aims. They found substantial variation in fluency aims for single component skills. For example, published aims for see/say multiplication facts up to the 9 times table, range from 40 correct answers with less than 3 errors to 90 correct answers with no errors. This lack of consistency represents a serious limitation in fluency research (Kubina, 2005). Until all researchers use the same fluency aims, it is difficult to compare results. Binder et al. (2002) present a set of fluency aims for a range of basic skills that they say are widely accepted among the precision teaching community. Consistent use of such a set of performance standards would enable researchers to compare results effectively.

The Importance of Practice There is much literature suggesting that practice is one of the most influential variables in both the acquisition and retention of skills (Binder, 1996; Doughty et al., 2004; Haughton, 1997; Johnson & Layng, 1996). Few teachers would disagree that newly acquired skills should be practiced. Indeed, it is common for teachers to provide practice sheets to be completed at school and as homework. Further, homilies such as `practice makes perfect' have been repeated by teachers and parents for generations. However, while educators agree that practice is important, there is little agreement on what form this practice should take and how long it should continue (Miller & Heward, 1992). Researchers have found that the number of practice trials required to reach 100% accuracy differs among individuals (Haughton, 1997; Ivarie, 1986). Practice involves repeating a response over time with the aim of improving that response (Kubina, 2005). Binder (1996, p. 179) defines practice as "the repetition of a given response class after it has been accurately established in a repertoire." Fischer et al.'s study (as cited in Peladeau et al., 2003) indicates that the amount of time spent on

12 academic tasks is highly correlated with academic achievement. But simply increasing time spent on academic tasks does not necessarily predict academic improvement. Some academic activities contribute more than others to the acquisition of skills and related academic success (Greenwood, Delquadri & Hall, 1984). Greenwood et al. (1984) found that the number of opportunities to respond, e.g., question asked (antecedent) followed by response (behaviour) followed by feedback on response (correct/incorrect), was a better predictor of success than time spent on academic tasks alone. The sequence of question, response and feedback is a type of controlled practice. Educationalists often describe traditional practice (rote learning) as outmoded and unproductive (Binder, 1996). Rote learning often conjures a picture of long periods of time spent practicing the same thing. Binder et al. (1995) and Binder (1996) suggest that practice for long periods of time may be punishing and is likely to be associated with decreased performance and task avoidance behaviour, particularly when response rate is well below fluency performance standards. Practice within the PT framework typically involves responding as many times as possible for short 1-min (or less) timings. Educationalists also suggest that rote learning is ineffective in aiding the acquisition of the more complex composite skills needed in our environments today (Binder, 1996). However, fluency research has suggested that this assertion is incorrect and that skills practiced to fluency will in fact increase the ease with which more complex composite skills are acquired (Binder, 1996). Binder suggests that this line of thought may have come about because practice, where performance is measured only with accuracy criteria, receives little reinforcement. The measurement of frequency that is part of fluency training allows improvements in performance during practice to be identified by teachers and thereby provides an opportunity for reinforcement.

13 Fluency building is one means of providing a large number of practice opportunities. It is commonly understood that fluency is achieved through repeated practice (Binder, 1996; Wolery et al., 1988). As an example of the primary role of practice in PT consider the Mornings