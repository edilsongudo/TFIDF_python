Text Augmentation: Inserting markup into natural language text with PPM Models

A thesis submitted in partial fulfilment of the requirements for the degree of Doctor of Philosophy at the University of Waikato by

Stuart A. Yeates

Department of Computer Science

Hamilton, New Zealand

July 9, 2006

ii

Abstract
This thesis describes a new optimisation and new heuristics for automatically marking up XML documents. These are implemented in CEM, using PPM models. CEM is significantly more general than previous systems, marking up large numbers of hierarchical tags, using n-gram models for large n and a variety of escape methods. Four corpora are discussed, including the bibliography corpus of 14682 bibliographies laid out in seven standard styles using the BIBTE system and markedX up in XML with every field from the original BIBTE Other corpora include the X. ROCLING Chinese text segmentation corpus, the Computists' Communique corpus and the Reuters' corpus. A detailed examination is presented of the methods of evaluating mark up algorithms, including computation complexity measures and correctness measures from the fields of information retrieval, string processing, machine learning and information theory. A new taxonomy of markup complexities is established and the properties of each taxon are examined in relation to the complexity of marked-up documents. The performance of the new heuristics and optimisation is examined using the four corpora. Keywords: hidden Markov models, HMM, PPM, Viterbi search, part-of-speech tagging, XML, markup, metadata.

iii

iv

Dedication
To Jacqui, my trapping state.

v

vi

Acknowledgements
Thank you my family, for always being there. Thank you David, Ian, Sally Jo and Matt for guidance, encouragement and technical help. Thank you to the Royal Society of New Zealand for funding through the Marsden Fund. Thank you to Reuters for the use of `Reuters Corpus, Volume 1, English language, 1996-08-20 to 1997-08-19'. Thank you to the ROCLING SIGIR for the use of the ROCLING corpus. Thank you to Kenneth I. Laws for the use of the Computists' Communique. Thank you to Pauline for handling the long-distance submission. Thank you my fellow students Carl, Catherine, Dana, Dave, David, Geoff, Gordon, Hayley, Imene, Jack, John, Justin, Karl, Kathy, Lin-Yi, Mark, Mark, Shane, Stuart, Yingying, and everyone else in the New Zealand Digital Library research group. Thank you to the tutoring, secretarial and technical staff. Thank you Aimee, Aliene, Amanda, Andraus, Andrew, Andrew, Andy, Anne, Anne, Barry, Belinda, Bill, Bob, Brent, Bret, Carolee, Caroline, Chris, Christine, Christine, Christine, Dale, Dave, Dave, David, David, Deborah, Dee, Des, Douglas, Erin, Erin, Gail Gayle, Gaylene, Georgina, Haylee, Ian, Jacqui, Jane, Janice, Jenny, Jenny, Kay, Kay, Kirsten, Kumar, Lee, Leigh, Leo, Linda, Lyn, Mandy, Matt, Maz, Micheal, Murray, Rachel, Rachel, Rachel, Rhonda, Roland, Rosie, Sam, Sam, Sara, Sarah, Shauna, Stuart, Sue, Terri, Terry, Terry, Toni, Tony, Wayne, Wendy and everyone else I've danced with in Christchurch, Hamilton, Auckland, London and Oxford during the course of my enrolment. Thank you to OUCS at Oxford for the use of their resources to finish this thesis. Thank you to all the RTS crew for their encouragement. Thanks to Sebastian for A the LTEX and XML help.

vii

viii

Contents
Dedication Acknowledgements Table of Contents List of Figures List of Tables List of Algorithms 1 Introduction 1.1 Plan of the Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2 Thesis Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . Background 2.1 The nature of text . . . . . . . . . . . . . . . . . 2.1.1 Ambiguity . . . . . . . . . . . . . . . . 2.1.2 Metadata . . . . . . . . . . . . . . . . . 2.2 Extraction of Textual Information . . . . . . . . 2.2.1 Regular Expressions . . . . . . . . . . . 2.2.2 Handcrafted Rules . . . . . . . . . . . . 2.2.3 Instance Based Machine Learning . . . . 2.2.4 Information Extraction . . . . . . . . . . 2.2.5 Markov Modelling . . . . . . . . . . . . 2.2.6 Trained versus Handcrafted Models . . . 2.2.7 Single Step versus Multiple Step Systems 2.3 Correctness . . . . . . . . . . . . . . . . . . . . 2.3.1 Recall and Precision . . . . . . . . . . . 2.3.2 Edit Distance . . . . . . . . . . . . . . . 2.3.3 Confusion Matrices . . . . . . . . . . . . 2.3.4 Entropy . . . . . . . . . . . . . . . . . . 2.3.5 Hybrid and Other Measures . . . . . . . 2.4 Efficiency . . . . . . . . . . . . . . . . . . . . . 2.5 XML Tags . . . . . . . . . . . . . . . . . . . . . 2.5.1 Nested Tags . . . . . . . . . . . . . . . . 2.5.2 Attributes of Tags . . . . . . . . . . . . . 2.5.3 Other Issues . . . . . . . . . . . . . . . . v vii xi xiv xv xvii 1 4 4 7 7 8 9 10 10 11 11 11 13 14 16 16 17 18 19 20 21 21 22 23 24 24

2

. . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . .

ix

3 Models and Algorithms 3.1 Markov Models . . . . . . . . 3.2 Hidden Markov Models . . . . 3.3 Higher Order Models . . . . . 3.4 Prediction by Partial Matching 3.5 Granularity of Models . . . . . 3.6 Searching in Models . . . . . 3.7 XML and Unicode . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

27 27 28 29 33 41 44 49 51 51 51 53 54 55 56 57 60 61 62 63 63 66 67 69 69 70 70 72 75 75 77 77 80 81 82 83 85 85 87 94 95

4 The System 4.1 Metadata . . . . . . . . . . . . . . . . . . . . . . . 4.1.1 Segmentation . . . . . . . . . . . . . . . . . 4.1.2 Classification . . . . . . . . . . . . . . . . . 4.1.3 Entity Extraction . . . . . . . . . . . . . . . 4.1.4 Limitations and Constraints . . . . . . . . . 4.2 Architecture . . . . . . . . . . . . . . . . . . . . . . 4.2.1 The Model . . . . . . . . . . . . . . . . . . 4.2.2 Differences between CEM and other systems 4.2.3 The Search Tree . . . . . . . . . . . . . . . 4.2.4 Full Exclusion . . . . . . . . . . . . . . . . 4.3 Optimisations and Heuristics . . . . . . . . . . . . . 4.3.1 Viterbi Optimisation . . . . . . . . . . . . . 4.3.2 Best First Optimisation . . . . . . . . . . . . 4.3.3 Automatic Tokenisation Heuristic . . . . . . 4.3.4 Alphabet Reduction . . . . . . . . . . . . . 4.3.5 Maximum Lookahead Heuristic . . . . . . . 4.3.6 TagC Heuristic . . . . . . . . . . . . . . . . 4.3.7 State Tying . . . . . . . . . . . . . . . . . . 4.4 Search Space . . . . . . . . . . . . . . . . . . . . . 4.4.1 The Semantics of Nested Tags . . . . . . . . 4.5 Teahan Search . . . . . . . . . . . . . . . . . . . . . 4.6 Evaluation . . . . . . . . . . . . . . . . . . . . . . . 4.6.1 Recall and Precision . . . . . . . . . . . . . 4.6.2 Edit Distance . . . . . . . . . . . . . . . . . 4.6.3 Confusion Matrices . . . . . . . . . . . . . . 4.6.4 Type Confusion Matrices . . . . . . . . . . . 4.6.5 Entropy . . . . . . . . . . . . . . . . . . . . 5 The Text 5.1 Computists' Corpus . 5.2 Bibliography Corpus 5.3 Segmentation Corpus 5.4 Reuters' Corpus . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

6 Results 97 6.1 PPM-SY versus PPMD . . . . . . . . . . . . . . . . . . . . . . . . 97 6.2 Correctness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99 x

6.3 6.4

6.2.1 Granularity and Heterogeneity . . . . 6.2.2 Computists' Corpus . . . . . . . . . 6.2.3 Bibliography Corpus . . . . . . . . . 6.2.4 Segmentation Corpus . . . . . . . . . 6.2.5 Reuters' Corpus . . . . . . . . . . . BaumÂ­Welch Re-estimation . . . . . . . . . Effectiveness of Optimisations and Heuristics 6.4.1 Best First . . . . . . . . . . . . . . . 6.4.2 Automatic Tokenisation . . . . . . . 6.4.3 Alphabet Reduction . . . . . . . . . 6.4.4 Maximum Lookahead Heuristic . . . 6.4.5 TagC Heuristic . . . . . . . . . . . . 6.4.6 State Tying . . . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

. . . . . . . . . . . . .

100 101 104 110 111 113 115 115 120 129 133 137 139 143 144 145 147 148 151 152 153 155 157 171 171 173 176 177

7

Conclusions 7.1 Review of Aims . . . . . . . . . . . . . . . . . . . 7.2 Performance of CEM and the New Techniques . . . 7.3 Impact of Unicode and Document Orientation . . . 7.4 Limitations of CEM . . . . . . . . . . . . . . . . . 7.5 Problems Suitable for CEM and Text Augmentation 7.6 Training Corpora Sizes . . . . . . . . . . . . . . . 7.7 Original Contributions . . . . . . . . . . . . . . . 7.8 Open Questions . . . . . . . . . . . . . . . . . . .

. . . . . . . .

. . . . . . . .

. . . . . . . .

. . . . . . . .

. . . . . . . .

. . . . . . . .

. . . . . . . .

. . . . . . . .

. . . . . . . .

Bibliography A Corpora Samples A.1 Computists' Corpus . A.2 Bibliography Corpus A.3 Segmentation Corpus A.4 Reuters' Corpus . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

xi

xii

List of Figures
2.1 2.2 3.1 3.2 3.3 3.4 3.5 3.6 3.7 4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 4.10 5.1 5.2 5.3 5.4 5.5 6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 6.10 6.11 6.12 Segmentation ambiguity in Chinese and Japanese . . . . . . . . . . 8 A limerick shown with and without secondary structure . . . . . . . 25 Isomorphism in Markov models . . . . . . . . . . . . . . . . . . Three representations of the PPMD model for Â·aabbccabca. . . . . The Â· model built from Â·abacbcbabÂ· . . . . . . . . . . . . . . The  model built from Â·abacbcbabÂ· . . . . . . . . . . . . . . The expansion step in a Viterbi search of Â·abbacbccbbab. . . . . . The next expansion step in a Viterbi search of Â·abbaccbcbbab. . . . The fourth expansion step in a Viterbi search of Â·abbaccbcbbab. . . Schema structures for segmentation and classification problems . Schema structure for the bibliography entity extraction problem The structure of a CEM model . . . . . . . . . . . . . . . . . . The structure of a PPM model . . . . . . . . . . . . . . . . . . Viterbi search of a large search space . . . . . . . . . . . . . . . Viterbi search fails . . . . . . . . . . . . . . . . . . . . . . . . The structure of a hidden Markov model, with state tying . . . . Teahan and Viterbi search comparison . . . . . . . . . . . . . . A short quote from Hamlet . . . . . . . . . . . . . . . . . . . . Inter-dependencies in a small entity extraction problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 36 38 39 40 41 42 52 55 57 59 64 65 71 76 78 80

Corrections in the Computists' Communique . . . . . . . . . . . Data-flow diagram for creating the bibliography collection . . . . Schema for the bibliography corpus with all tags . . . . . . . . . Schema for bibliography corpus with tags used in this thesis (with state tying) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Schema for the bibliography corpus without state tying . . . . . . PPMD and PPM-SY in the Computists' corpus . . . . . PPMD and PPM-SY in the segmentation corpus . . . . . Correctness for documents in the Reuters' corpus . . . . Correctness for the Reuters' corpus . . . . . . . . . . . . BaumÂ­Welch re-estimation . . . . . . . . . . . . . . . . Best first in the bibliography corpus (hierarchical) . . . . Best first in the bibliography corpus (non-hierarchical) . Best first for varying model orders . . . . . . . . . . . . Effect of best first and the number of training documents Effect of tokenisation on a group of hierarchical tags . . Effect of tokenisation on a group of non-hierarchical tags Interaction between best first and tokenisation . . . . . . xiii . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

. 86 . 90 . 91 . 93 . 93 . . . . . . . . . . . . 98 99 112 113 114 116 117 118 119 122 123 128

6.13 6.14 6.15 6.16 6.17 6.18 6.19

The effects of alphabet reduction on finding a single tag . . . . . The effects of alphabet reduction on finding multiple tags . . . . Lookahead for the name tag . . . . . . . . . . . . . . . . . . . Lookahead for the word tag . . . . . . . . . . . . . . . . . . . . The TagC heuristic in the bibliography corpus (hierarchical) . . The TagC heuristic in the bibliography corpus (non-hierarchical) Entropy dropping with increased training data . . . . . . . . . .

. . . . . . .

. . . . . . .

130 132 135 136 137 138 141

xiv

List of Tables
2.1 3.1 3.2 4.1 6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 6.10 6.11 6.12 6.13 6.14 6.15 6.16 6.17 Metadata at different granularities . . . . . . . . . . . . . . . . . . 10 A variety of linguistic problems tackled with HMMs . . . . . . . . 28 n-gram models and models of order k . . . . . . . . . . . . . . . . 31 Search space size . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 Confusion matrices for the Computists' corpus . . . . . . . . . . Accuracy for the Computists' corpus . . . . . . . . . . . . . . . . Confusion matrix for the bibliography corpus without note . . . . Confusion matrix for the bibliography corpus with note . . . . . . Type confusion matrix for the bibliography corpus for many tags . Example of effect of model size on defects . . . . . . . . . . . . . Segmentation of Chinese . . . . . . . . . . . . . . . . . . . . . . Occurrence tables for the Reuters' corpus . . . . . . . . . . . . . Occurrence tables for the bibliography corpus . . . . . . . . . . . Interaction between errors . . . . . . . . . . . . . . . . . . . . . Occurrence tables for the Computists' corpus . . . . . . . . . . . Occurrence tables for the segmentation corpus . . . . . . . . . . . Folders used in alphabet reduction . . . . . . . . . . . . . . . . . Example of effect of lookahead on defects . . . . . . . . . . . . . Lookahead for the word tag . . . . . . . . . . . . . . . . . . . . . Type confusion matrices, with and without state tying (many tags) Type confusion matrices, with and without state tying (few tags) . . . . . . . . . . . . . . . . . . 102 103 104 106 108 109 110 121 125 126 126 127 129 134 136 140 142

xv

xvi

List of Algorithms
1 2 3 4 The complete search algorithm The Viterbi search algorithm . The Teahan search algorithm . The BaumÂ­Welch algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 45 46 47

xvii

Chapter 1 Introduction
Timely news is in great demand, and the value increases if the news is tightly focused on specific areas of interest to the readers. Often readers are interested in specific organisations, dates and sources, so the fragment:
1997 was a record spending year for computer-industry mergers and acquisitions, and companies such as Compaq, Dell, IBM, and Hewlett-Packard are still hot to buy what's left. [InfoWorld Electric, 24Dec97. EduP.]

might be considerably more valuable to a reader if the organisations, dates and sources of information were marked up with <o> <d> and <s> tags, respectively:
<d>1997</d>was a record <d>spending year</d>for computer-industry mergers and acquisitions, and companies such as <o>Compaq</o>, <o>Dell</o>, <o>IBM</o>, and <o>Hewlett-Packard</o>are still hot to buy what's left. <s>EduP</s>.] [<s>InfoWorld Electric</s>, <d>24Dec97</d>.

The extraction of references to company names in particular forms the backbone of systems such as finance.yahoo.com, which aggregate news from many hundreds of sources into thousands of tightly focused categories. Languages such as Chinese and Japanese are usually written without whitespace segmenting the characters into words. One of the first operations that must be performed by many information systems dealing with such text is to augment it with segmentation information, for example: 1 is augmented to

<w>

</w><w>

</w><w>

</w><w> </w><w>

</w>, ([ele-

mentary school][building interior][sports][area][construction], i.e. the construction of an elementary school indoor sports arena). Such segmented text can then be used in all the ways that words from a western language can be used [3]. The tags can then be discarded to display the text in the original form or used to process the text in the word-by-word fashion common to most western information systems, or some combination of the two. There are many thousands, perhaps many millions, of peer-reviewed academic papers available on the Internet, each with bibliographic entries linking it to other papers and materials, for example:
Donald E. Knuth. Semantics of context-free languages. Mathematical System Theory, 1968, 2(2), 127Â­145.

A competent researcher or librarian can readily separate this entry into all the parts necessary to find the document to which it refers. When there are collections of thousands of electronic documents, separating these manually is a huge, tedious and error-prone task. What would be useful would be a system that took the entry and automatically augmented it as:
<entry> <author> <forenames>Donald E.</forenames> <surname>Knuth </surname>. </author> <title>Semantics of context-free languages</title>. <journal>Mathematical System Theory</journal>, <year>1968</year>, <volume>2</volume>(<number>2</number>), <pages>127-145</pages>. </entry>

2

Data in such an augmented format could then be used in a number of operations, including interloaning a copy of the document, reformatting the reference for inclusion in another bibliography, citation analysis and querying by date. Digital library software is increasingly interacting with non-computer specialists on their own terms. This can be done using generic interfaces (witness the success of the slim-line Google interface) or interfaces tailored to the domain of the users or the content. In order to provide this, the digital library needs to know what those terms are and how they apply to the documents in the collections, whether they are organisations, dates and sources or authors, titles and dates of publication. Manual augmentation with this knowledge is typically expensive, slow and inconsistent. This thesis describes a method for automating text augmentations for a large class of problems covering all of these examples. Such text augmentation is performed by building models from training text marked-up with XML tags, then using the models and searching to insert similar tags into testing text that does not yet contain any tags. Building effective models requires considerable volumes of training text with consistently used tags, and that the training text be representative of testing text. The text augmentation described in this thesis covers a broader range of information than preceding approaches, but is shallower than most information extraction systems in that all reasoning is fine-grained, with no higher-level or document-level reasoning, limiting the text augmentations that can be attempted. The quality of text augmentation is evaluated by splitting a marked-up corpus into a set of training documents and a set of testing documents; training a model on the former; stripping the tags from the latter; augmenting the stripped testing documents using the model; and finally comparing the testing documents as augmented by the system with the original documents. Several different methods to compare the augmented document to the original are explored in this thesis. 3

1.1

Plan of the Thesis

Following this introduction, Chapter 2 gives the background to the current work, starting by examining the nature of text and an overview of methods of extracting information from text. Approaches to evaluating the correctness and efficiency of the such extractions are then examined, together with ways on encoding extracted information in XML. Chapter 3 introduces Markov models built from text, and algorithms for search using such models to extract information. Chapter 4 discusses the architecture of the implemented system, and examines the rationale for some of the design choices. It then presents an optimisation and a number of heuristics, and examines the search spaces of different classes of problems with respect to these. Chapter 5 introduces the corpora used in this thesis. Chapter 6 sets out the experimental results of the optimisation and heuristics on the corpora. Chapter 7 concludes the thesis with an overview of the research, a list of the original contributions, and a summary of unanswered questions. The appendix contains samples from each of the corpora used in this work.

1.2

Thesis Statement

Text augmentation is the automated insertion of XML tags into documents in the context of a digital library to make implicit textual information accessible to conventional processing. Text augmentation can be expanded to a larger class of problems than those previously studied. It can be partitioned into three classes of problem: segmentation, classification and entity extraction. Each class of problem has distinctive properties, computational complexity and types of failure, necessitating different evaluation methodologies. Markov models and searching can be used to solve these problems. Given the context of their application, there are a number of optimisa4

tions and heuristics which can be used to make these algorithms computationally tractable. Text augmentation is a computational process by which natural language text is augmented by the addition of XML tags to elucidate the implicit structure. Three different classes of text augmentation are discussed. Each class has a structurally different schema which affects the performance and evaluation of text augmentation. Text augmentation is performed using statistical modelling techniques, such as hidden Markov and PPM models, and using searching algorithms to find a good augmentation. In the past, text augmentation has been performed using Teahan search (see Section 4.5), but in this thesis a variety of algorithms is used. Viterbi search is computationally intractable in many interesting text augmentation situations, but an optimisation of it, and a number of heuristics to it, can be exploited, given the application, to make searching computationally feasible. To these ends, this thesis aims to: 1. Examine text augmentation problems, in the large, to attempt to determine which are susceptible to automated text augmentation and whether some sets of problems are inherently easier than others. 2. Build a text augmentation system capable of solving at least as wide a range of problems as existing low-human-input systems, with an eye to eventual inclusion as part of a digital library system. 3. Locate and/or build corpora to test this system. 4. Find specific heuristics and optimisations which perform well in relation to a particular set of augmentation problems. 5. Evaluate both the text augmentation system and the heuristics and optimisations in the system. 5

These aims are reviewed in Section 7.1.

6

Chapter 2 Background
This chapter examines the background to the current work. First it looks at the nature of text, various types of ambiguities in natural language text and then examines metadata, namely explicit information about text. Information extraction systems, whose purpose is to extract metadata from text, are then surveyed and various methods of evaluating such extraction systems are examined, together with methods of evaluating the correctness and efficiency of such systems. Finally, aspects of XML and Unicode relevant to text augmentation are surveyed.

2.1

The nature of text

One task in text augmentation is the Chinese text segmentation problem, the task of segmenting a stream of Chinese characters into words. The task is often the first step in Chinese information processing systems, since Chinese is normally written without explicit word delimiters. The task is made more challenging by the fact that line delimiters may occur anywhere, including between letters in a word or digits in a number [42]. The task is harder than it appears because Chinese text is ambiguous. The text shown in Figure 2.1(a)(i) (taken from [137]) can be segmented as shown in (ii) or as shown in (iii), meaning `I like New Zealand flowers' and `I like fresh broccoli' respectively. Similarly the Japanese title shown in Figure 2.1(b)(i) (taken from [3]) can be segmented as shown in (ii) or as shown in (iii) meaning `president both business and general manager' and `president (of) subsidiary business (for) (the proper 7

(i)

(ii) (a) Chinese

(iii)

(i)

(ii) (b) Japanese

(iii)

Figure 2.1: Examples of segmentation ambiguity in east Asian languages.

name) Tsutomu, general manager' respectively. Since this last is four nouns and thus identical from the point of view of a part of speech system, it is a particularly ambiguous situation.

2.1.1 Ambiguity
Segmentation ambiguity is not confined to Asian languages. There is a widely circulated joke featuring sentence segmentation ambiguity in English: Dear John: I want a man who knows what love is all about. You are generous, kind, thoughtful. People who are not like you admit to being useless and inferior. You have ruined me for other men. I yearn for you. I have no feelings whatsoever when we're apart. I can be forever happy--will you let me be yours? Gloria and Dear John: I want a man who knows what love is. All about you are generous, kind, thoughtful people, who are not like you. Admit to being useless and inferior. You have ruined me. For other men, I yearn. For you, I have no feelings whatsoever. When we're apart, I can be forever happy. Will you let me be? Yours, Gloria

8

There is an entire class of English expression, double entendre, which exploits ambiguity of meaning [128]. This ambiguity is resolved using context--the style and genre of a piece of text. A sentence with two possible meanings has the more risquÂ´ meaning if it appears in a Blackadder [38] script and has the less risquÂ´ of e e the two if it appears in a Reuters' dispatch. There are also forms of text in which resolving ambiguity of meaning is not possible, a well-known example of which is Lewis Carroll's poem `Jabberwocky'. Ambiguity resolution using context is an example of what is known in artificial intelligence as `common sense reasoning'. It is known to be difficult for computers to resolve such ambiguity, with the difficulty lying in the wide range of world-knowledge and subtle reasoning that humans use to solve this class of problem [107]. Partly to reduce the need for ambiguity resolution, the overwhelming majority of text mining is performed on collections of text with uniform style and genre. Uniformity of linguistic style highlights the patterns and structures within the text and the uniformity of genre ensures that the patterns have the same meanings.

2.1.2 Metadata
Metadata means `a set of data that describes and gives data about other data' [128]. Usually at the granularity of the document (the catalogue entry for a book or the title and author of a web page), metadata can be at the character level [5] or cover entire collections of documents (Table 2.1). In many systems and standards much of the metadata is stored at the document level, even though it may apply to the collection, section or even character level, because this is the level at which most processing, storage, licensing, retrieval and transmission operations take place. The RDF standard [156] is notable for granularity independence, addressing, individual tags (elements), documents or collections of documents. This thesis centres on fine-grained metadata, at the character and word levels, 9

Granularity Relevant metadata Collection Scope; purpose; coverage; copyright; maintenance status; maintainer contact details; Document Author; title; date of publication; subject classification; Section Topics; cross references; Sentence Semantic meanings; Word Part of speech; glossary links; dictionary links; collation order; Character Encoding; reading direction; case;

Table 2.1: Metadata at different granularities. and how such metadata can be inferred from, and then annotated into, the text itself. This process of augmenting the text is referred to as text augmentation. It has been previously called `tag insertion' [136, 135], but the author believes that `text augmentation' better portrays the action and intent of the process.

2.2

Extraction of Textual Information

A wide range of distinct approaches and many hybrid ones have been used to extract fine-grained information from text for various purposes. This section reviews several of them, including regular expressions, machine learning and information extraction. The following section examines how to measure the correctness of the extraction.

2.2.1 Regular Expressions
Regular expressions are compact representations of a set of strings which can be converted into a finite-state machine. The machine can efficiently recognise instances of the set of strings within a stream of text. Their close relationship to the well-studied field of formal language parsing has led to them being well understood [2]. Regular expressions are the tool of choice for extracting information with an exact and precise format, such as email addresses, post codes, dates and the like.

10

They are, however, fragile in the face of mistakes, ambiguity and stylistic variations in the text.

2.2.2 Handcrafted Rules
Handcrafted rules or templates can also be used to extract information from text. These typically involve searching for short fragments of text or regular expressions within text, with each rule processed in order of precedence. Unfortunately, systems of handcrafted rules can be complex and fragile in the face changing input data. They also scale poorly with the number classes of information being extracted, particularly when there is a requirement that rules do not overlap. These systems typically can consider large windows and potentially have access to `out of band' sources of information such as dictionaries and name lists [17, 1, 74].

2.2.3 Instance Based Machine Learning
Instance based machine learning is a field concerned primarily with classifying instances into classes. Machine learning can be applied to text [149], but requires that the text be pre-segmented into instances, potentially losing significant information and/or leading to large instances. Machine learning handles noise and ambiguity significantly better than regular expressions. Mis-classified instances, once detected, can be added incrementally to the training instances, allowing an existing model to be refined and improved. The widely-used Brill tagger [28] uses this approach as a primary method.

2.2.4 Information Extraction
The field of information extraction typically involves multi-step systems that first extract atoms from text (using regular expressions, part-of-speech tagging, etc.) and

11

then use higher-order reasoning to solve `real world' problems. The Text REtrieval Conferences series (TREC) [53, 54, 142, 143] is built round text retrieval tasks and the Message Understanding Conferences (MUC) and Document Understanding Conferences (DUC) are built around competitions between systems. The intent is to focus research and systems development towards specific, known targets. MUC Named Entity [35] problems centre on the extraction of proper nouns (e.g. company names), often with s